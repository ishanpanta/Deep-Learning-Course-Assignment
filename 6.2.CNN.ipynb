{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLkK0iuX1_2V"
      },
      "source": [
        "\n",
        "\n",
        "Import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY_hfczt1_2Z"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-9InSYa1_2a",
        "outputId": "0017a225-f5f7-48a6-9b5b-c4a254ed4c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
            "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        }
      ],
      "source": [
        "mnist = input_data.read_data_sets(\"data/mnist\",one_hot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk7FQ_LU1_2b"
      },
      "outputs": [],
      "source": [
        "batch_size = 50\n",
        "epsilon = 1e-9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co9T1uv31_2c"
      },
      "outputs": [],
      "source": [
        "def squash(sj):\n",
        "\n",
        "    sj_norm = tf.reduce_sum(tf.square(sj), -2, keep_dims=True)\n",
        "    scalar_factor = sj_norm / (1 + sj_norm) / tf.sqrt(sj_norm + epsilon)\n",
        "\n",
        "    vj = scalar_factor * sj\n",
        "\n",
        "    return vj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S8IiRUm1_2d"
      },
      "outputs": [],
      "source": [
        "def dynamic_routing(ui, bij, num_routing=10):\n",
        "\n",
        "    #initialize weights wij by drawing from a random normal distribution\n",
        "    wij = tf.get_variable('Weight', shape=(1, 1152, 160, 8, 1), dtype=tf.float32,\n",
        "                                  initializer=tf.random_normal_initializer(0.01))\n",
        "\n",
        "    #initialize biases with a constant value\n",
        "    biases = tf.get_variable('bias', shape=(1, 1, 10, 16, 1))\n",
        "\n",
        "    #define the primary capsules: (tf.tile replicates the tensor n times)\n",
        "    ui = tf.tile(ui, [1, 1, 160, 1, 1])\n",
        "\n",
        "    #compute the prediction vector\n",
        "    u_hat = tf.reduce_sum(wij * ui, axis=3, keep_dims=True)\n",
        "\n",
        "    #reshape the prediction vector\n",
        "    u_hat = tf.reshape(u_hat, shape=[-1, 1152, 10, 16, 1])\n",
        "\n",
        "    #stop gradient computation in the prediction vector\n",
        "    u_hat_stopped = tf.stop_gradient(u_hat, name='stop_gradient')\n",
        "\n",
        "    #perform dynamic routing for number of routing iterations\n",
        "    for r in range(num_routing):\n",
        "\n",
        "        #refer dynamic routing algorithm in the book for the detailed explanation on the following steps\n",
        "        with tf.variable_scope('iter_' + str(r)):\n",
        "\n",
        "            #step 1\n",
        "            cij = tf.nn.softmax(bij, dim=2)\n",
        "\n",
        "            #step 2\n",
        "            if r == num_routing - 1:\n",
        "\n",
        "                sj = tf.multiply(cij, u_hat)\n",
        "\n",
        "                sj = tf.reduce_sum(sj, axis=1, keep_dims=True) + biases\n",
        "\n",
        "                vj = squash(sj)\n",
        "\n",
        "            elif r < num_routing - 1:\n",
        "\n",
        "                sj = tf.multiply(cij, u_hat_stopped)\n",
        "\n",
        "                sj = tf.reduce_sum(sj, axis=1, keep_dims=True) + biases\n",
        "\n",
        "                vj = squash(sj)\n",
        "\n",
        "                vj_tiled = tf.tile(vj, [1, 1152, 1, 1, 1])\n",
        "\n",
        "                coupling_coeff = tf.reduce_sum(u_hat_stopped * vj_tiled, axis=3, keep_dims=True)\n",
        "\n",
        "                #step 3\n",
        "                bij += coupling_coeff\n",
        "\n",
        "    return vj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Jjlz-vM1_2d"
      },
      "outputs": [],
      "source": [
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default() as g:\n",
        "\n",
        "    #placeholders for the input and output\n",
        "    x = tf.placeholder(tf.float32, [batch_size, 784])\n",
        "    y = tf.placeholder(tf.float32, [batch_size,10])\n",
        "\n",
        "    #reshape the input x\n",
        "    x_image = tf.reshape(x, [-1,28,28,1])\n",
        "\n",
        "    #perform the convolutional operation and get the convolutional input,\n",
        "    with tf.name_scope('convolutional_input'):\n",
        "        input_data = tf.contrib.layers.conv2d(inputs=x_image, num_outputs=256,\n",
        "                                              kernel_size=9, padding='valid')\n",
        "\n",
        "\n",
        "    #compute the primary capsules which extract the basic features such as edges.\n",
        "    #first, compute the capsules using convolution operation:\n",
        "    capsules = []\n",
        "\n",
        "    for i in range(8):\n",
        "\n",
        "        with tf.name_scope('capsules_' + str(i)):\n",
        "\n",
        "            #convolution operation\n",
        "            output = tf.contrib.layers.conv2d(inputs=input_data, num_outputs=32,kernel_size=9,\n",
        "                                              stride=2, padding='valid')\n",
        "\n",
        "            #reshape the output\n",
        "            output = tf.reshape(output, [batch_size, -1, 1, 1])\n",
        "\n",
        "            #store the output which is capsule in the capsules list\n",
        "            capsules.append(output)\n",
        "\n",
        "    #concatenate all the capsules and form the primary capsule\n",
        "    primary_capsule = tf.concat(capsules, axis=2)\n",
        "\n",
        "    #squash the primary capsule and get the probability i.e apply squash function and get the probability\n",
        "    primary_capsule = squash(primary_capsule)\n",
        "\n",
        "\n",
        "    #compute digit capsules using dynamic routing\n",
        "    with tf.name_scope('dynamic_routing'):\n",
        "\n",
        "        #reshape the primary capsule\n",
        "        outputs = tf.reshape(primary_capsule, shape=(batch_size, -1, 1, primary_capsule.shape[-2].value, 1))\n",
        "\n",
        "        #initialize bij with 0s\n",
        "        bij = tf.constant(np.zeros([1, primary_capsule.shape[1].value, 10, 1, 1], dtype=np.float32))\n",
        "\n",
        "        #compute the digit capsules using dynamic routing algorithm which takes\n",
        "        #the reshaped primary capsules and bij as inputs and returns the activity vector\n",
        "        digit_capsules = dynamic_routing(outputs, bij)\n",
        "\n",
        "    digit_capsules = tf.squeeze(digit_capsules, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK9h9Y5a1_2e"
      },
      "outputs": [],
      "source": [
        "with graph.as_default() as g:\n",
        "    with tf.variable_scope('Masking'):\n",
        "\n",
        "        # select the activity vector of given input image using the actual label y and mask out others\n",
        "        masked_v = tf.multiply(tf.squeeze(digit_capsules), tf.reshape(y, (-1, 10, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQxOM74f1_2e"
      },
      "outputs": [],
      "source": [
        "with graph.as_default() as g:\n",
        "\n",
        "    with tf.name_scope('Decoder'):\n",
        "\n",
        "        #masked digit capsule\n",
        "        v_j = tf.reshape(masked_v, shape=(batch_size, -1))\n",
        "\n",
        "        #first fully connected layer\n",
        "        fc1 = tf.contrib.layers.fully_connected(v_j, num_outputs=512)\n",
        "\n",
        "        #second fully connected layer\n",
        "        fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024)\n",
        "\n",
        "        #reconstructed image\n",
        "        reconstructed_image = tf.contrib.layers.fully_connected(fc2, num_outputs=784, activation_fn=tf.sigmoid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQe6iqT91_2e"
      },
      "outputs": [],
      "source": [
        "with graph.as_default() as g:\n",
        "    with tf.variable_scope('accuracy'):\n",
        "\n",
        "        #compute the length of each activity vector in the digit capsule\n",
        "        v_length = tf.sqrt(tf.reduce_sum(tf.square(digit_capsules), axis=2, keep_dims=True) + epsilon)\n",
        "\n",
        "        #apply softmax to the length and get the probabilities\n",
        "        softmax_v = tf.nn.softmax(v_length, dim=1)\n",
        "\n",
        "        #select the index which got the highest probability this will give us the predicted digit\n",
        "        argmax_idx = tf.to_int32(tf.argmax(softmax_v, axis=1))\n",
        "        predicted_digit = tf.reshape(argmax_idx, shape=(batch_size, ))\n",
        "\n",
        "        #compute the accuracy\n",
        "        actual_digit = tf.to_int32(tf.argmax(y, axis=1))\n",
        "\n",
        "        correct_pred = tf.equal(predicted_digit,actual_digit)\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQgsaQ981_2f"
      },
      "outputs": [],
      "source": [
        "lambda_ = 0.5\n",
        "alpha = 0.0005\n",
        "\n",
        "with graph.as_default() as g:\n",
        "\n",
        "    #margin loss\n",
        "    max_left = tf.square(tf.maximum(0.,0.9 - v_length))\n",
        "    max_right = tf.square(tf.maximum(0., v_length - 0.1))\n",
        "\n",
        "    T_k = y\n",
        "\n",
        "    #compute margin loss L_k for class k as given in (2)\n",
        "    L_k = T_k * max_left + lambda_ * (1 - T_k) * max_right\n",
        "\n",
        "    #compute total margin as given in refer equation (3)\n",
        "    margin_loss = tf.reduce_mean(tf.reduce_sum(L_k, axis=1))\n",
        "\n",
        "    #reshape and get the original image\n",
        "    original_image = tf.reshape(x, shape=(batch_size, -1))\n",
        "\n",
        "    #compute reconstruction loss as shown in (4)\n",
        "    squared = tf.square(reconstructed_image - original_image)\n",
        "    reconstruction_loss = tf.reduce_mean(squared)\n",
        "\n",
        "    #compute total loss which is the weighted sum of margin and reconstructed loss as shown in (5)\n",
        "    total_loss = margin_loss + alpha * reconstruction_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00qG4K0R1_2f"
      },
      "outputs": [],
      "source": [
        "with graph.as_default() as g:\n",
        "    optimizer = tf.train.AdamOptimizer(0.0001).minimize(total_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q13JW-oe1_2f"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "num_steps = int(len(mnist.train.images)/batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsHAdOp61_2h",
        "outputId": "9daba4ae-3acf-4ccd-b9d9-82a4ce2ac236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, iteration:0, Loss:0.553201019764 Accuracy: 0.140000000596\n",
            "Epoch: 0, iteration:10, Loss:0.543244898319 Accuracy: 0.119999997318\n",
            "Epoch: 0, iteration:20, Loss:0.531144499779 Accuracy: 0.119999997318\n",
            "Epoch: 0, iteration:30, Loss:0.526307284832 Accuracy: 0.119999997318\n",
            "Epoch: 0, iteration:40, Loss:0.526460289955 Accuracy: 0.140000000596\n"
          ]
        }
      ],
      "source": [
        "with tf.Session(graph=graph) as sess:\n",
        "\n",
        "    init_op = tf.global_variables_initializer()\n",
        "    sess.run(init_op)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for iteration in range(num_steps):\n",
        "            batch_data, batch_labels = mnist.train.next_batch(batch_size)\n",
        "            feed_dict = {x : batch_data, y : batch_labels}\n",
        "\n",
        "            _, loss, acc = sess.run([optimizer, total_loss, accuracy], feed_dict=feed_dict)\n",
        "\n",
        "            if iteration%10 == 0:\n",
        "                print('Epoch: {}, iteration:{}, Loss:{} Accuracy: {}'.format(epoch,iteration,loss,acc))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}